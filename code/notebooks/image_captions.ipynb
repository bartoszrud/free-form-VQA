{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e960094a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pathlib\n",
    "import os\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68c902a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/home/bartek/ETH/CS4NLP/project/free-form-VQA/code\")\n",
    "from vqa import VQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e249d45f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/bartek/ETH/CS4NLP/project/free-form-VQA/code')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_imgs_path = \"/home/bartek/ETH/CS4NLP/project/train2014\"\n",
    "val_imgs_path = \"/home/bartek/ETH/CS4NLP/project/val2014\"\n",
    "random.seed(2137)\n",
    "pathlib.Path.cwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba06e6e",
   "metadata": {},
   "source": [
    "## Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dee75122",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = \"/home/bartek/ETH/CS4NLP/project/coco/PythonAPI\"\n",
    "dataType='train2014'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e5630d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.52s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "annFile = '{}/annotations/captions_{}.json'.format(dataDir,dataType)\n",
    "coco_caps=COCO(annFile)\n",
    "img_ids = coco_caps.getImgIds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e637e4c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'license': 3,\n",
       " 'file_name': 'COCO_train2014_000000506066.jpg',\n",
       " 'coco_url': 'http://images.cocodataset.org/train2014/COCO_train2014_000000506066.jpg',\n",
       " 'height': 640,\n",
       " 'width': 480,\n",
       " 'date_captured': '2013-11-18 10:05:46',\n",
       " 'flickr_url': 'http://farm6.staticflickr.com/5100/5427769651_4226e3ddec_z.jpg',\n",
       " 'id': 506066}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco_caps.loadImgs(img_ids[np.random.randint(0,len(img_ids))])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8bee39f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4139"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_ids_subsample = random.sample(img_ids,int(0.05*len(img_ids)))\n",
    "len(image_ids_subsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "085d5551",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57870\n",
      "a sheep and two babies in the grass\n",
      "\n",
      "A is sheep grazing and her lambs are resting.\n",
      "A mother animal and her babies eating grass.\n",
      "A sheep grazing next to her baby sheep in a green grass covered field.\n",
      "Three lambs, one adult and two smalls ones on a green pasture.\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "annIds = coco_caps.getAnnIds(imgIds=image_ids_subsample[i])\n",
    "print(img_ids[0])\n",
    "anns = coco_caps.loadAnns(annIds)\n",
    "coco_caps.showAnns(anns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a5f1c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading VQA annotations and questions into memory...\n",
      "0:00:06.324631\n",
      "creating index...\n",
      "index created!\n",
      "loading VQA annotations and questions into memory...\n",
      "0:00:01.778774\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "vqa = VQA(annotation_file= \"../data/v2_mscoco_train2014_annotations.json\", question_file=\"../data/v2_OpenEnded_mscoco_train2014_questions.json\")\n",
    "vqa_val = VQA(annotation_file= \"../data/v2_mscoco_val2014_annotations.json\", question_file=\"../data/v2_OpenEnded_mscoco_val2014_questions.json\")\n",
    "\n",
    "q_ids_train = vqa.getImgIds()\n",
    "q_ids_val = vqa_val.getImgIds()\n",
    "q_ids_all = q_ids_train+q_ids_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6513d608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "581929"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(q_ids_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d69811e",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_set = [\"What can be seen in this image?\", \"What is in this image?\", \"What this image depicts?\"]\n",
    "\n",
    "\n",
    "\n",
    "q_id = max(q_ids_all)\n",
    "\n",
    "annotations = []\n",
    "questions = []\n",
    "\n",
    "for i in range(len(image_ids_subsample)):\n",
    "    question_idx = random.randint(0,2) \n",
    "    annIds = coco_caps.getAnnIds(imgIds=image_ids_subsample[i])\n",
    "    anns = coco_caps.loadAnns(annIds)\n",
    "\n",
    "    capt = [an[\"caption\"] for an in anns]\n",
    "    annot = {\"question_type\": \"describe image\",\"answers\": capt,\"image_id\": image_ids_subsample[i],\n",
    "             \"answer_type\": \"caption\", \"question_id\": q_id}\n",
    "    annotations.append(annot)\n",
    "    q_item = {\"question_id\" : q_id, \"image_id\": image_ids_subsample[i], \n",
    "              \"question\" : questions_set[question_idx]}\n",
    "    questions.append(q_item)\n",
    "    q_id+=1\n",
    "    \n",
    "next_qid = q_id+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460e6338",
   "metadata": {},
   "source": [
    "# annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80973869",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"annotations_training.json\", \"w\") as f:\n",
    "    json.dump({\"annotations\": annotations}, f )\n",
    "    \n",
    "with open(\"questions_training.json\", \"w\") as q:\n",
    "    json.dump({\"questions\": questions}, q)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cb6bfa",
   "metadata": {},
   "source": [
    "## Validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "785d97f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = \"/home/bartek/ETH/CS4NLP/project/coco/PythonAPI\"\n",
    "dataType='val2014'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52880436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.25s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2025"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annFile = '{}/annotations/captions_{}.json'.format(dataDir,dataType)\n",
    "coco_caps=COCO(annFile)\n",
    "img_ids = coco_caps.getImgIds()\n",
    "image_ids_subsample = random.sample(img_ids,int(0.05*len(img_ids)))\n",
    "len(image_ids_subsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4f3597a",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_ids = [299334,299335, 299336]\n",
    "questions_set = [\"What can be seen in this image?\", \"What is in this image?\", \"What this image depicts?\"]\n",
    "\n",
    "assert question_ids not in q_ids_all\n",
    "\n",
    "annotations = []\n",
    "questions = []\n",
    "\n",
    "for i in range(len(image_ids_subsample)):\n",
    "    question_idx = random.randint(0,2) \n",
    "    annIds = coco_caps.getAnnIds(imgIds=image_ids_subsample[i])\n",
    "    anns = coco_caps.loadAnns(annIds)\n",
    "\n",
    "    capt = [an[\"caption\"] for an in anns]\n",
    "    annot = {\"question_type\": \"describe image\",\"answers\": capt,\"image_id\": image_ids_subsample[i],\n",
    "             \"answer_type\": \"caption\", \"question_id\": next_qid}\n",
    "    annotations.append(annot)\n",
    "    q_item = {\"question_id\" : next_qid, \"image_id\": image_ids_subsample[i], \n",
    "              \"question\" : questions_set[question_idx]}\n",
    "    questions.append(q_item)\n",
    "    next_qid+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2cbedbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"annotations_validation.json\", \"w\") as f:\n",
    "    json.dump({\"annotations\": annotations}, f )\n",
    "    \n",
    "with open(\"questions_validation.json\", \"w\") as q:\n",
    "    json.dump({\"questions\": questions}, q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299db427",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
