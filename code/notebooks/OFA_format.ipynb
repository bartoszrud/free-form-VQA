{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "082749c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import base64\n",
    "import pickle\n",
    "import warnings \n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b67f379",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(action='ignore')\n",
    "SEED=42\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34f830bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/annotations/questions_validation.json\", \"r\") as f_q:\n",
    "    questions_val = json.load(f_q)\n",
    "\n",
    "    \n",
    "with open(\"../../data/annotations/annotations_validation.json\", \"r\") as f_a:\n",
    "    annotations_val = json.load(f_a)\n",
    "    \n",
    "with open(\"../../data/annotations/questions_training.json\", \"r\") as f_q:\n",
    "    questions_train = json.load(f_q)\n",
    "\n",
    "    \n",
    "with open(\"../../data/annotations/annotations_training.json\", \"r\") as f_a:\n",
    "    annotations_train = json.load(f_a)\n",
    "\n",
    "train_imgs_path = \"/home/bartek/ETH/CS4NLP/project/train2014\"\n",
    "val_imgs_path = \"/home/bartek/ETH/CS4NLP/project/val2014\"\n",
    "# test_imgs_path = \"/home/bartek/ETH/CS4NLP/project/train2015\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24c9e52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special(input_string):\n",
    "    final_string = \"\"\n",
    "    for character in input_string:\n",
    "        if  character == \" \":\n",
    "            final_string = final_string + character\n",
    "        else:\n",
    "            if(character.isalnum()):\n",
    "                final_string = final_string + character\n",
    "\n",
    "    return final_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "faff9a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraction = 0.1\n",
    "no_samples_train = int(fraction*len(questions_train[\"questions\"]))\n",
    "no_samples_dev = 300\n",
    "no_samples_val = int(fraction*len(questions_val[\"questions\"]))\n",
    "\n",
    "q_train_subset, a_train_subset = zip(*random.sample(\n",
    "    list(zip(questions_train[\"questions\"], annotations_train[\"annotations\"])),no_samples_train))\n",
    "\n",
    "q_val_subset, a_val_subset = zip(*random.sample(\n",
    "    list(zip(questions_val[\"questions\"], annotations_val[\"annotations\"])),no_samples_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41cd5d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46410\n",
      "40155\n",
      "40138\n"
     ]
    }
   ],
   "source": [
    "ans2label = {}\n",
    "\n",
    "answers_all = []\n",
    "\n",
    "    \n",
    "\n",
    "for annotation in a_train_subset:\n",
    "    if isinstance(annotation[\"answers\"], list):\n",
    "        for answer in annotation[\"answers\"]:\n",
    "            answers_all.append(answer)\n",
    "\n",
    "    else:\n",
    "        answers_all.append(annotation[\"answers\"])\n",
    "\n",
    "\n",
    "print(len(answers_all))\n",
    "\n",
    "answers_all = set(answers_all)\n",
    "print(len(answers_all))\n",
    "answers_all = [remove_special(answer) for answer in answers_all]\n",
    "answers_all = set(answers_all)\n",
    "print(len(answers_all))\n",
    "\n",
    "\n",
    "for i, answer in enumerate(list(answers_all)):\n",
    "    ans2label[answer] = i\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "506acdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ans2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "184ad89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_ans2label_01_fixed.pkl\", \"wb\") as f:\n",
    "    pickle.dump(ans2label,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea8bbcd",
   "metadata": {},
   "source": [
    "## Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80dd89ed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 44789/44789 [09:52<00:00, 75.61it/s]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns = [\"question-id\", \"image-id\", \"question\", \"answer\", \"labels\", \"image\"])\n",
    "\n",
    "img_prefix = \"/COCO_train2014_\"\n",
    "\n",
    "\n",
    "for question, annotation in tqdm(zip(q_train_subset, a_train_subset), total=len(a_train_subset)):\n",
    "    if question[\"image_id\"] != annotation[\"image_id\"]:\n",
    "        raise ValueError(\"Q&A not alligned!\")\n",
    "        \n",
    "\n",
    "    filename = train_imgs_path + img_prefix+str(question[\"image_id\"]).zfill(12)+\".jpg\"\n",
    "    \n",
    "    img = Image.open(filename)\n",
    "    img_buffer = BytesIO()\n",
    "    img.save(img_buffer, format=img.format)\n",
    "    byte_data = img_buffer.getvalue()\n",
    "    base64_str = base64.b64encode(byte_data) # bytes\n",
    "    base64_str = base64_str.decode(\"utf-8\") # str\n",
    "\n",
    "    if isinstance(annotation[\"answers\"], list):\n",
    "        for answer in annotation[\"answers\"]:\n",
    "\n",
    "\n",
    "            new_record = {\"question-id\": question[\"question_id\"], \n",
    "                          \"image-id\":question[\"image_id\"], \"question\":remove_special(question[\"question\"]),\n",
    "                          \"answer\":'1.0|!+'+remove_special(answer), \n",
    "                          \"labels\":\"a\", \"image\": base64_str}\n",
    "            df = df.append(new_record, ignore_index=True)\n",
    "    else:\n",
    "        new_record = {\"question-id\": question[\"question_id\"], \n",
    "                          \"image-id\":question[\"image_id\"], \"question\":remove_special(question[\"question\"]),\n",
    "                          \"answer\":'1.0|!+'+remove_special(annotation[\"answers\"]), \n",
    "                          \"labels\":\"a\", \"image\": base64_str}\n",
    "        df = df.append(new_record, ignore_index=True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e25ca9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_dev= train_test_split(df, test_size=no_samples_dev, random_state=SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "624020f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(\"vqa_train_sub01_fixed.tsv\", sep = \"\\t\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4991ea26",
   "metadata": {},
   "source": [
    "## Dev dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fba78302",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev.to_csv(\"vqa_dev_300_01_fixed.tsv\", sep = \"\\t\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06080b88",
   "metadata": {},
   "source": [
    "## Validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2772cb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 21637/21637 [04:20<00:00, 83.13it/s]\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns = [\"question-id\", \"image-id\", \"question\", \"answer\", \"labels\", \"image\"])\n",
    "\n",
    "img_prefix = \"/COCO_val2014_\"\n",
    "\n",
    "for question, annotation in tqdm(zip(q_val_subset, a_val_subset), total = len(a_val_subset)):\n",
    "    if question[\"image_id\"] != annotation[\"image_id\"]:\n",
    "        raise ValueError(\"Q&A not alligned!\")\n",
    "        \n",
    "\n",
    "    filename = val_imgs_path + img_prefix+str(question[\"image_id\"]).zfill(12)+\".jpg\"\n",
    "    \n",
    "    img = Image.open(filename)\n",
    "    img_buffer = BytesIO()\n",
    "    img.save(img_buffer, format=img.format)\n",
    "    byte_data = img_buffer.getvalue()\n",
    "    base64_str = base64.b64encode(byte_data) # bytes\n",
    "    base64_str = base64_str.decode(\"utf-8\") # str\n",
    "\n",
    "    \n",
    "    if isinstance(annotation[\"answers\"], list):\n",
    "        for answer in annotation[\"answers\"]:\n",
    "\n",
    "            new_record = {\"question-id\": question[\"question_id\"], \n",
    "                          \"image-id\":question[\"image_id\"], \"question\":remove_special(question[\"question\"]),\n",
    "                          \"answer\":'1.0|!+'+remove_special(answer), \n",
    "                          \"labels\":\"a\", \"image\": base64_str}\n",
    "            df = df.append(new_record, ignore_index=True)\n",
    "        \n",
    "    else:\n",
    "        new_record = {\"question-id\": question[\"question_id\"], \n",
    "                          \"image-id\":question[\"image_id\"], \"question\":remove_special(question[\"question\"]),\n",
    "                          \"answer\":'1.0|!+'+remove_special(annotation[\"answers\"]), \n",
    "                          \"labels\":\"a\", \"image\": base64_str}\n",
    "        df = df.append(new_record, ignore_index=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e22d9fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.to_csv(\"vqa_val_sub01_fixed.tsv\", sep = \"\\t\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6b468c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22329\n"
     ]
    }
   ],
   "source": [
    "print(len(df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
